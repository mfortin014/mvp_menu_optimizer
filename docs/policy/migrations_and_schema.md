# Migrations & Schema Discipline

**Updated:** 2025-09-18 21:20

Purpose: keep database drift under control while the MVP evolves. Pair with `dump_schema.sh` and the RLS specs before altering data models.

---

## Source of Truth

### MVP now

- **Migrations:** append-only SQL files under `migrations/sql/` named `V###__short_desc.sql`.
- **Schema snapshot:** `schema/current/supabase_schema_<env>.sql` reflects the latest dump for each Bitwarden project (e.g., `supabase_schema_prod.sql`).
- **Release history:** each shipped version gets a frozen dump in `schema/releases/` (generated by `dump_schema.sh`).

### v1 later

- Managed migrations (Alembic/Flyway) and automated schema diffs will backfill GitHub discussions before execution.
- Additional schema slices (analytics, reporting replicas) get their own directories and policies.

---

## Authoring a Migration

### Bootstrap baseline (V000)

- `migrations/sql/V000__bootstrap_schema.sql` rebuilds the database exactly as it existed on 2025-09-09 before V001.
- It is scoped to app-owned objects (`public.*` plus required extensions like `pgcrypto`/`uuid-ossp`) so it runs cleanly on a fresh Supabase project.
- Keep the file deterministic: strip non-essential statements (`SET`, `COMMENT`, `GRANT`, ownership) so migrations remain reproducible.

### MVP now

1. Create a new SQL file with the next sequence number (`V015__add_example_table.sql`).
2. Write **idempotent** statements: guard `CREATE` with `IF NOT EXISTS`, prefer views over data rewrites.
3. Include rollback notes in the file header comment (manual until we adopt reversible tooling).
4. Test locally against a disposable Supabase instance before opening a PR.
5. Document the change in the relevant spec or changelog entry.

### v1 later

- Codify forward/rollback scripts per migration and run them through automated CI sandboxes.
- Introduce migration linting (check for locks, `SET ROLE`, etc.).

---

## Refreshing Schema Dumps

### MVP now
- Never hand-edit files under `schema/`.  
- After deploying a migration, run `./dump_schema.sh --env prod --mode release --tag <release-name>`, then:
  - Commit the updated `schema/current/supabase_schema_prod.sql`.
  - Commit the release snapshot `schema/releases/supabase_schema_prod_<release-name>.sql`.
- The script also keeps timestamped snapshots in `schema/archive/` (ignored by Git) for local forensics.

### v1 later

- Automate schema refresh on release tagging and attach dumps to GitHub Releases.
- Maintain per-environment snapshots (staging/prod) for diffing in CI.

---

## Running Migrations

### MVP now
- Choose the Bitwarden project explicitly:
  - `./migrate.sh --env staging up --dry-run`  
    (`--env <name>` must match an export in `.envrc`; use `--project-id <uuid>` when running outside direnv.)
  - Drop `--dry-run` to apply changes once the plan looks clean.
- Optional driver override: `./migrate.sh --env staging --driver postgresql+psycopg up`.
- Idempotent bookkeeping:
  - `./migrate.sh --env staging mark V012__backfill.sql`
  - `./migrate.sh --env staging mark-before V015__cutoff.sql`
- The script resolves `DATABASE_URL` via `bws run --project-id=â€¦ -- python -m utils.db`; no `.env` sourcing or legacy `DB_URL` fallbacks remain.

### v1 later
- Wire migrations into CI sandbox runs and require automated dry-runs before production promotion.

---

## Data Safety

- Avoid destructive ops (`DROP`, `DELETE`) unless the accompanying spec approves it.
- Seed data lives under `data/exports/`; the lightweight fixtures for tests live in `data/fixtures/` (no secrets).
- When altering reference data, update the relevant source `.md` documents (Data Dictionary, changelog).
